{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model Life-Cycle\n",
    "A model has a life-cycle, and this very simple knowledge provides the backbone for both modeling a dataset and understanding the tf.keras API.\n",
    "\n",
    "The five steps in the life-cycle are as follows:\n",
    "\n",
    "1.Define the model.\n",
    "2.Compile the model.\n",
    "3.Fit the model.\n",
    "4.Evaluate the model.\n",
    "5.Make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP for Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(235, 34) (116, 34) (235,) (116,)\n",
      "Test Accuracy: 0.905\n",
      "1/1 [==============================] - 1s 556ms/step\n",
      "Predicted: 0.980\n"
     ]
    }
   ],
   "source": [
    "# MLP for Binary Classification\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# load the dataset\n",
    "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv'\n",
    "df = read_csv(path, header=None)\n",
    "# split into input and output columns\n",
    "X, y = df.values[:, :-1], df.values[:, -1]\n",
    "# ensure all data are floating point values\n",
    "X = X.astype('float32')\n",
    "# encode strings to integer\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "# split into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "# determine the number of input features\n",
    "n_features = X_train.shape[1]\n",
    "#print(n_features)\n",
    "# define model****************************************************************************************\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
    "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model***********************************************************************************\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# fit the model***************************************************************************************\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0)\n",
    "# evaluate the model**********************************************************************************\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Accuracy: %.3f' % acc)\n",
    "#print(loss)\n",
    "# make a prediction***********************************************************************************\n",
    "row = [1,0,0.99539,-0.05889,0.85243,0.02306,0.83398,-0.37708,1,0.03760,0.85243,-0.17755,0.59755,-0.44945,0.60536,-0.38223,0.84356,-0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,-0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,-0.34090,0.42267,-0.54487,0.18641,-0.45300]\n",
    "#row = [0,0,\t0,\t0,\t0,\t0\t,1,\t-1,\t0\t,0,\t-1,\t-1,\t0,\t0,\t0,\t0\t,1,\t1,\t-1,\t-1,\t0\t,0\t,0\t,0\t,1,\t1,\t1,\t1,\t0,\t0,\t1,\t1,\t0\t,0]\n",
    "yhat = model.predict([row])\n",
    "print('Predicted: %.3f' % yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.905\n",
      "1/1 [==============================] - 1s 527ms/step\n",
      "Predicted: 0.015\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Accuracy: %.3f' % acc)\n",
    "\n",
    "# make another prediction\n",
    "row = [0,0,0,0,0,0,1,-1,0,0,-1,-1,0,0,0,0,1,1,-1,-1,0,0,0,0,1,1,1,1,0,0,1,1,0,0]\n",
    "yhat = model.predict([row])\n",
    "print('Predicted: %.3f' % yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP for Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4) (50, 4) (100,) (50,)\n",
      "Test Accuracy: 0.480\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "Predicted: [[0.7400407  0.03793481 0.22202443]] (class=0)\n"
     ]
    }
   ],
   "source": [
    "# mlp for multiclass classification\n",
    "from numpy import argmax\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# load the dataset\n",
    "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv'\n",
    "df = read_csv(path, header=None)\n",
    "# split into input and output columns\n",
    "X, y = df.values[:, :-1], df.values[:, -1]\n",
    "# ensure all data are floating point values\n",
    "X = X.astype('float32')\n",
    "# encode strings to integer\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "#print(y)\n",
    "# split into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "# determine the number of input features\n",
    "n_features = X_train.shape[1]\n",
    "# define model****************************************************************************************\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
    "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "# compile the model***********************************************************************************\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# fit the model***************************************************************************************\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0)\n",
    "# evaluate the model**********************************************************************************\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Accuracy: %.3f' % acc)\n",
    "# make a prediction***********************************************************************************\n",
    "row = [5.1,3.5,1.4,0.2]\n",
    "#row = [6.9,3.2,5.7,2.3]\n",
    "#row = [5.7,2.8,4.5,1.3]\n",
    "yhat = model.predict([row])\n",
    "print('Predicted: %s (class=%d)' % (yhat, argmax(yhat)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" In this case above, we can see that the model achieved a classification accuracy of about 96 percent and \n",
    "then predicted a probability of a row of data belonging to each class, although class 0 has the highest \n",
    "probability.\n",
    "\n",
    "(100, 4) (50, 4) (100,) (50,)\n",
    "Test Accuracy: 0.960\n",
    "Predicted: [[9.991980e-01 6.892086e-04 1.127535e-04]] (class=0) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.480\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Predicted: [[0.07266169 0.48792592 0.43941233]] (class=1)\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Accuracy: %.3f' % acc)\n",
    "\n",
    "# make second prediction\n",
    "row = [6.9,3.2,5.7,2.3]\n",
    "yhat = model.predict([row])\n",
    "print('Predicted: %s (class=%d)' % (yhat, argmax(yhat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" In this case above, we can see that the model achieved a classification accuracy of about 96 percent and \n",
    "then predicted a probability of a row of data belonging to each class, although class 2 has the highest \n",
    "probability.\n",
    "\n",
    "(100, 4) (50, 4) (100,) (50,)\n",
    "Test Accuracy: 0.960\n",
    "Predicted: [[0.00249702 0.20922099 0.78828204]] (class=2) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.480\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Predicted: [[0.1417356  0.43934757 0.4189169 ]] (class=1)\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Accuracy: %.3f' % acc)\n",
    "\n",
    "# make third prediction\n",
    "row = [5.7,2.8,4.5,1.3]\n",
    "yhat = model.predict([row])\n",
    "print('Predicted: %s (class=%d)' % (yhat, argmax(yhat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" In this case above, we can see that the model achieved a classification accuracy of about 96 percent and \n",
    "then predicted a probability of a row of data belonging to each class, although class 1 has the highest \n",
    "probability.\n",
    "\n",
    "(100, 4) (50, 4) (100,) (50,)\n",
    "Test Accuracy: 0.960\n",
    "Predicted: [[0.01029302 0.53254884 0.45715812]] (class=1) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(339, 13) (167, 13) (339,) (167,)\n",
      "MSE: 62.509, RMSE: 7.906\n",
      "WARNING:tensorflow:6 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000024B09FB5750> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 448ms/step\n",
      "Predicted: 33.010\n"
     ]
    }
   ],
   "source": [
    "# mlp for regression\n",
    "from numpy import sqrt\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# load the dataset\n",
    "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'\n",
    "df = read_csv(path, header=None)\n",
    "# split into input and output columns\n",
    "X, y = df.values[:, :-1], df.values[:, -1]\n",
    "# split into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "# determine the number of input features\n",
    "n_features = X_train.shape[1]\n",
    "#print(n_features)\n",
    "# define model****************************************************************************************\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
    "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(1))\n",
    "# compile the model***********************************************************************************\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit the model***************************************************************************************\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0)\n",
    "# evaluate the model**********************************************************************************\n",
    "error = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('MSE: %.3f, RMSE: %.3f' % (error, sqrt(error)))\n",
    "# make a prediction***********************************************************************************\n",
    "row = [0.00632,18.00,2.310,0,0.5380,6.5750,65.20,4.0900,1,296.0,15.30,396.90,4.98]\n",
    "#row = [0.17004,12.5,7.87,0,0.524,6.004,85.9,6.5921,5,311,15.2,386.71,17.1]\n",
    "\n",
    "yhat = model.predict([row])\n",
    "print('Predicted: %.3f' % yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 62.509, RMSE: 7.906\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Predicted: 19.342\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "error = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('MSE: %.3f, RMSE: %.3f' % (error, sqrt(error)))\n",
    "\n",
    "# make second prediction\n",
    "row = [0.17004,12.5,7.87,0,0.524,6.004,85.9,6.5921,5,311,15.2,386.71,17.1]\n",
    "yhat = model.predict([row])\n",
    "print('Predicted: %.3f' % yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 62.509, RMSE: 7.906\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "Predicted: 17.585\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "error = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('MSE: %.3f, RMSE: %.3f' % (error, sqrt(error)))\n",
    "\n",
    "# make third prediction\n",
    "row = [0.22489,12.5,7.87,0,0.524,6.377,94.3,6.3467,5,311,15.2,392.52,20.45]\n",
    "yhat = model.predict([row])\n",
    "print('Predicted: %.3f' % yhat)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "94bf681353f1dffb28520a0e2441c93b8d70873e6e12f4bede32d467f74315bc"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
